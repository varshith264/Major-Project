{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIkxm7-elYX7",
        "outputId": "5ca7e9c7-4172-4fe3-86dc-68581f4e904e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hmmlearn  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-VBHJgaljzt",
        "outputId": "2fcd5df1-25b3-4fea-8507-53b9a2cc77c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.2.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (374 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 374 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.7/dist-packages (from hmmlearn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from hmmlearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.7/dist-packages (from hmmlearn) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16->hmmlearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16->hmmlearn) (1.1.0)\n",
            "Installing collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.2.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from hmmlearn.hmm import GaussianHMM, GMMHMM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm "
      ],
      "metadata": {
        "id": "qB2H8BpVlx64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import logging\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from hmmlearn.hmm import GaussianHMM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from docopt import docopt"
      ],
      "metadata": {
        "id": "gWNcdlbql0V9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/S7 Project/BTC.csv')\n",
        "data = data[4278:47892]"
      ],
      "metadata": {
        "id": "nn4o1Vlbl3rR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(data, test_size=0.2, shuffle=False)"
      ],
      "metadata": {
        "id": "JZ5XIzdFl4Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features\n",
        "def extract_features(data):\n",
        "    open_price = np.array(data['Open'])\n",
        "    close_price = np.array(data['Close'])\n",
        "    high_price = np.array(data['High'])\n",
        "    low_price = np.array(data['Low'])\n",
        "    frac_change = (close_price - open_price) / open_price\n",
        "    frac_high = (high_price - open_price) / open_price\n",
        "    frac_low = (open_price - low_price) / open_price\n",
        "    return np.column_stack((frac_change, frac_high, frac_low))\n"
      ],
      "metadata": {
        "id": "v_twIj11l9_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_most_probable_outcome(day_index):\n",
        "    previous_data_start_index = max(0, day_index - 20)\n",
        "    previous_data_end_index = max(0, day_index - 1)\n",
        "    previous_data = test_data.iloc[previous_data_end_index: previous_data_start_index]\n",
        "    previous_data_features = extract_features(previous_data)\n",
        "\n",
        "    outcome_score = []\n",
        "    for possible_outcome in possible_outcomes:\n",
        "        total_data = np.row_stack(\n",
        "            (previous_data_features, possible_outcome))\n",
        "        outcome_score.append(model.score(total_data))\n",
        "    most_probable_outcome = possible_outcomes[np.argmax(\n",
        "        outcome_score)]\n",
        "\n",
        "    return most_probable_outcome"
      ],
      "metadata": {
        "id": "DbBDfkWhmA20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#All possible outcomes\n",
        "frac_change_range = np.linspace(-0.1, 0.1, 60)\n",
        "frac_high_range = np.linspace(0, 0.1, 10)\n",
        "frac_low_range = np.linspace(0, 0.1, 10)\n",
        "possible_outcomes = np.array(list(itertools.product(\n",
        "    frac_change_range, frac_high_range, frac_low_range)))\n"
      ],
      "metadata": {
        "id": "xc8jBSq_mBQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GMMHMM(n_components=4, n_mix=5)\n",
        "model.fit(extract_features(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE7HQnv-mGaA",
        "outputId": "45dc5db2-aea1-4b1e-92c2-50626c69e215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GMMHMM(covars_prior=array([[[-1.5, -1.5, -1.5],\n",
              "        [-1.5, -1.5, -1.5],\n",
              "        [-1.5, -1.5, -1.5],\n",
              "        [-1.5, -1.5, -1.5],\n",
              "        [-1.5, -1.5, -1.5]],\n",
              "\n",
              "       [[-1.5, -1.5, -1.5],\n",
              "        [-1.5, -1.5, -1.5],\n",
              "        [-1.5, -1.5, -1.5],\n",
              "        [-1.5, -1.5, -1.5],\n",
              "        [-1.5, -1.5, -1.5]],\n",
              "\n",
              "       [[-1.5, -1.5, -1.5],\n",
              "        [-1.5, -1.5, -1.5],\n",
              "        [-1.5, -1.5, -1.5],\n",
              "        [-1.5, -1.5, -1.5],\n",
              "        [-1.5, -1.5, -1.5]],\n",
              "\n",
              "       [[-1.5, -1.5, -1.5],\n",
              "        [-1.5, -1.5, -1.5],\n",
              "        [-1.5, -1.5, -1.5],\n",
              "        [-1.5, -1.5...\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]]]),\n",
              "       means_weight=array([[0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.]]),\n",
              "       n_components=4, n_mix=5,\n",
              "       weights_prior=array([[1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = []\n",
        "for day_index in tqdm(range(len(test_data))):\n",
        "  open_price = test_data.iloc[day_index]['Open']\n",
        "  predicted_frac_change, _, _ = get_most_probable_outcome(day_index)\n",
        "  open_price * (1 + predicted_frac_change)\n",
        "  predicted.append(open_price * (1 + predicted_frac_change))\n",
        "with open('/content/drive/MyDrive/project/checking.txt', 'w') as filehandle:\n",
        "  for listitem in predicted:\n",
        "    filehandle.write(str(listitem)+\", \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koEa8fKEmL2k",
        "outputId": "f2479cf3-4b93-4d2d-9171-cee4e2c491b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 700/700 [1:01:48<00:00,  5.30s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/S7 Project/BTC.csv')\n",
        "data = data[4278:47892]\n",
        "close = data.Close\n",
        "train,test = train_test_split(\n",
        "            close, test_size=0.2, shuffle=False)\n",
        "actual=test.tolist()"
      ],
      "metadata": {
        "id": "0sFudkp8mOwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "rmse = mean_squared_error(predicted, actual , squared=False)\n",
        "print(\"rmse: \" +str(rmse))\n",
        "\n",
        "mape=0\n",
        "for i in range(len(actual)):\n",
        "  mape+=abs(actual[i]-predicted[i])/actual[i]\n",
        "mape/=len(actual)\n",
        "print(\"mape: \" +str(mape))\n",
        "\n",
        "\n",
        "absolute_prediction_errors=[]\n",
        "for i in range(len(actual)):\n",
        "  absolute_prediction_errors.append(abs(actual[i]-predicted[i]))\n",
        "absolute_prediction_errors = sorted(absolute_prediction_errors)\n",
        "mean = sum(absolute_prediction_errors) / len(absolute_prediction_errors)\n",
        "sd = 0\n",
        "for i in absolute_prediction_errors:\n",
        "  sd += (i-mean)**2\n",
        "sd/=len(absolute_prediction_errors)\n",
        "sd=pow(sd,0.5)\n",
        "minimum = absolute_prediction_errors[0]\n",
        "a25 = absolute_prediction_errors[(int)(25*len(absolute_prediction_errors))//100]\n",
        "a50 = absolute_prediction_errors[(int)(50*len(absolute_prediction_errors))//100]\n",
        "a75 = absolute_prediction_errors[(int)(75*len(absolute_prediction_errors))//100]\n",
        "a95 = absolute_prediction_errors[(int)(95*len(absolute_prediction_errors))//100]\n",
        "a97 = absolute_prediction_errors[(int) (97.5*len(absolute_prediction_errors))//100]\n",
        "maximum = absolute_prediction_errors[-1]\n",
        "\n",
        "print(mean)\n",
        "print(sd)\n",
        "print(minimum)\n",
        "print(a25)\n",
        "print(a50)\n",
        "print(a75)\n",
        "print(a95)\n",
        "print(a97)\n",
        "print(maximum)"
      ],
      "metadata": {
        "id": "P4YFanpWYIuY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "GMMHMM",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}